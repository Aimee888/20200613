# 多线程爬虫
## 前言
在掌握了requests与正则表达式以后，就可以开始实战爬取一些简单的网址了。  
但是，此时的爬虫只有一个进程、一个线程，因此称为单线程爬虫。单线程爬
虫每次只访问一个页面，不能充分利用计算机的网络带宽。一个页面最多也就
几百KB，所以爬虫在爬取一个页面的时候，多出来的网速和从发起请求得到的
源代码中间的时间都被浪费掉了。  
如果可以让爬虫同时访问10个页面，就相当于爬取速度提高了10倍。为了达到
这个目的，就需要使用多线程技术了。  
这里有一点要强调，Python语言在设计的时候，有一个全局解释器锁（Global
 Interpreter Lock, GIL）。这导致Python的多线程都是伪多线程，即本质上
还是一个线程，但是每个线程每个事情只做几毫秒，几毫秒以后就保存现场，
换做其他事情，一轮之后回到第一件事上，恢复现场再做几毫秒，继续换……
微观上的单线程，在宏观上就像同时在做几件事。这种机制在I/O（Input/Output
，输入/输出）密集型的操作上影响不大，但是在CPU计算密集型的操作上面，由于
只能使用CPU的一个核，就会对性能产生非常大的影响。所以涉及计算密集型的程
序，就需要使用多进程，Python的多进程不受GIL的影响。  
爬虫属于I/O密集型的程序，所以使用多线程可以大大提高爬取效率  
## 多进程库
multiprocessing  
&emsp;&emsp;multiprocessing本身是Python的多进程库，用来处理与多进程相关的
操作。但是由于进程与进程之间不能直接共享内存和堆栈资源，而且启动新的进程
开销也比线程大得多，因此使用多线程来爬取比使用多进程有更多的优势。
multiprocessing下面有一个dummy模块，它可以让Python的线程使用multiprocessing
的各种方法。  
&emsp;&emsp;dummy下面有一个Pool类，它用来实现线程池。这个线程池有一个map()方法，可以让
线程池里面的所有线程都“同时”执行一个函数。如：thread_study.py  
&emsp;&emsp;对比单线程爬虫和多线程爬虫爬取百度首页的性能差异。visit_baidu.py  



 